{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import packages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import gc\n",
    "from client import client\n",
    "import torch\n",
    "from server import server_multinomial_bitflip, server_multinomial_genrr, server_ell2\n",
    "from data_generator import create_power_law, data_generator\n",
    "import time\n",
    "import numpy as np\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Change settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n"
     ]
    }
   ],
   "source": [
    "d = 3                       # data dimension; choose from {3,4,5}\n",
    "n_bin = 4                   # fixed at 4 in the paper\n",
    "privacy_level = 1           # privacy level \\alpha: choose from {0.5, 1, 2}\n",
    "sample_size   = 6000        \n",
    "n_permutation = 999         # fixed at 999 in the paper\n",
    "priv_mech  = 'bitflip' #choose among 'bitflip', 'genrr', 'lapu', 'disclapu'\n",
    "statistic  = 'elltwo' #choose among 'chi', 'projchi', 'elltwo'. chi requires 1-dimensional multinomial data.\n",
    "n_test        = 2000        \n",
    "test_start    = 1\n",
    "significance_level = 0.05\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(torch.get_num_threads())\n",
    "###################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create data generator, client, and server instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_gen = data_generator() #create data generator\n",
    "LDPclient = client() #create the client, which privatizes the data\n",
    "\n",
    "method_name = priv_mech + statistic\n",
    "\n",
    "server_private_vec = {\n",
    "    \"elltwo\":server_ell2(privacy_level),\n",
    "    \"chi\":server_multinomial_genrr(privacy_level),\n",
    "    \"projchi\":server_multinomial_bitflip(privacy_level)\n",
    "    }\n",
    "server_private = server_private_vec[statistic] #create the server, which conducts the test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the simulations #############################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "genrrelltwo, alpha=1, sample size=1000\n",
      "#########################################\n",
      "pval: [0.094] -- 1th test, time elapsed 0.9477024078369141 -- emperical power so far (from test_start): 0.0\n",
      "pval: [0.85600001] -- 2th test, time elapsed 0.9870755672454834 -- emperical power so far (from test_start): 0.0\n",
      "pval: [0.177] -- 3th test, time elapsed 1.042029619216919 -- emperical power so far (from test_start): 0.0\n",
      "pval: [0.92400002] -- 4th test, time elapsed 1.0669326782226562 -- emperical power so far (from test_start): 0.0\n",
      "pval: [0.17900001] -- 5th test, time elapsed 0.9474873542785645 -- emperical power so far (from test_start): 0.0\n",
      "pval: [0.44100001] -- 6th test, time elapsed 1.0135388374328613 -- emperical power so far (from test_start): 0.0\n",
      "pval: [0.24699999] -- 7th test, time elapsed 1.007143259048462 -- emperical power so far (from test_start): 0.0\n",
      "pval: [0.35800001] -- 8th test, time elapsed 1.0061941146850586 -- emperical power so far (from test_start): 0.0\n",
      "pval: [0.052] -- 9th test, time elapsed 1.0131371021270752 -- emperical power so far (from test_start): 0.0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_2136\\1093885143.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     39\u001b[0m     \u001b[0mtime_now\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutcnow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrftime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'%Y-%m-%d %H:%M:%S'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 41\u001b[1;33m     \u001b[0mp_value_vec\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstatistic_vec\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mserver_private\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelease_p_value_permutation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_permutation\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     42\u001b[0m     \u001b[0mt_end_i\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mt_start_i\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"pval: {p_value_vec[i]} -- {test_num}th test, time elapsed {t_end_i} -- emperical power so far (from test_start): {(p_value_vec[0:(i+1)] < significance_level).mean()}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\GitHub\\optimal-local-dp-two-sample\\server.py\u001b[0m in \u001b[0;36mrelease_p_value_permutation\u001b[1;34m(self, n_permutation)\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_permutation\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 42\u001b[1;33m             \u001b[0mpermuted_statistic_vec\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_statistic\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandperm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_1\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_2\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     43\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m         \u001b[1;32mreturn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_p_value_proxy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpermuted_statistic_vec\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moriginal_statistic\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moriginal_statistic\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\GitHub\\optimal-local-dp-two-sample\\server.py\u001b[0m in \u001b[0;36m_get_statistic\u001b[1;34m(self, perm)\u001b[0m\n\u001b[0;32m    121\u001b[0m         \u001b[1;31m# Get row sums\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    122\u001b[0m         \u001b[0my_row_sum\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_sum_y\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mperm\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 123\u001b[1;33m         \u001b[0mz_row_sum\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_sum_z\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mperm\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    124\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    125\u001b[0m         \u001b[1;31m# Calculate y_sqrsum and z_sqrsum\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\GitHub\\optimal-local-dp-two-sample\\server.py\u001b[0m in \u001b[0;36mget_sum_z\u001b[1;34m(self, perm)\u001b[0m\n\u001b[0;32m     79\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget_sum_z\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mperm\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     80\u001b[0m         \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mperm_toZ_fromY\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mperm_toZ_fromZ\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit_perm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mperm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 81\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata_y\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mperm_toZ_fromY\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda_device_z\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata_z\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mperm_toZ_fromZ\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     82\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     83\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget_mean_y\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mperm\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print(f\"{method_name}, alpha={privacy_level}, sample size={sample_size}\")\n",
    "print(\"#########################################\")\n",
    "p_value_vec = np.zeros([n_test, 1])\n",
    "statistic_vec = np.zeros([n_test, 1])\n",
    "t = time.time()\n",
    "\n",
    "for i in range(n_test):\n",
    "    test_num = i + test_start\n",
    "    t_start_i = time.time()\n",
    "    torch.manual_seed(test_num)\n",
    "    copula_mean = torch.zeros(d).to(device)\n",
    "\n",
    "    copula_sigma_1 = (0.5 * torch.ones(d,d) + 0.5 * torch.eye(d)).to(device)\n",
    "    copula_sigma_2 = copula_sigma_1.mul(5)\n",
    "\n",
    "    data_y_priv = LDPclient.release_private_conti(\n",
    "            priv_mech,\n",
    "            data_gen.generate_copula_gaussian_data(sample_size, copula_mean, copula_sigma_1),\n",
    "            privacy_level,\n",
    "            n_bin,\n",
    "            device\n",
    "        )\n",
    "\n",
    "    data_z_priv = LDPclient.release_private_conti(\n",
    "            priv_mech,\n",
    "            data_gen.generate_copula_gaussian_data(sample_size, copula_mean, copula_sigma_2),\n",
    "            privacy_level,\n",
    "            n_bin,\n",
    "            device\n",
    "        )\n",
    "\n",
    "    server_private.load_private_data_multinomial(\n",
    "        data_y_priv,\n",
    "        data_z_priv,\n",
    "        LDPclient.alphabet_size_binned,\n",
    "        device,\n",
    "        device\n",
    "    )\n",
    "    time_now = datetime.utcnow().strftime('%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "    p_value_vec[i], statistic_vec[i] = server_private.release_p_value_permutation(n_permutation)\n",
    "    t_end_i = time.time() - t_start_i\n",
    "    print(f\"pval: {p_value_vec[i]} -- {test_num}th test, time elapsed {t_end_i} -- emperical power so far (from test_start): {(p_value_vec[0:(i+1)] < significance_level).mean()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LDPUtsEnvK40_windows",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
