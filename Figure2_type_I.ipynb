{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import packages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from client import client\n",
    "import torch\n",
    "from server import server_ell2, server_multinomial_genrr, server_multinomial_bitflip\n",
    "from data_generator import data_generator\n",
    "import time\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Change settings ################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_size = 500 # choose from {500, 1000, 1500}\n",
    "n_test = 10\n",
    "n_permutation = 999\n",
    "significance_level = 0.05 # change continuously from .01 to .99\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fixed settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = 500 #fixed at k=500 in the paper\n",
    "privacy_level = 0.1 # fixed at alpha=0.1 in the paper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### choose between the following two settings of the probability vector:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = torch.arange(1,d).float().reciprocal() #multinomial probability vector for the power law setting\n",
    "#p = torch.ones(d) # multinomial probability vector for the uniform law setting\n",
    "#####################################################\n",
    "p = p.divide(p.sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create data generator, client, and server instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_gen = data_generator() #create data generator\n",
    "LDPclient = client() #create the client, which privatizes the data\n",
    "server_private_vec = {\n",
    "    \"elltwo\":server_ell2(privacy_level),\n",
    "    \"chi\":server_multinomial_genrr(privacy_level),\n",
    "    \"projchi\":server_multinomial_bitflip(privacy_level)\n",
    "    }\n",
    "server_list = [\"elltwo\", \"chi\", \"projchi\"]\n",
    "privmech_list = [\"lapu\", \"genrr\", \"bitflip\"]\n",
    "p_value_array = np.zeros([n_test, 3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lapu + elltwo, permutation test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1th test\n",
      "2th test\n",
      "3th test\n",
      "4th test\n",
      "5th test\n",
      "6th test\n",
      "7th test\n",
      "8th test\n",
      "9th test\n",
      "10th test\n",
      "11.305525541305542\n"
     ]
    }
   ],
   "source": [
    "\n",
    "t = time.time()\n",
    "for i in range(n_test):\n",
    "    print(f\"{i+1}th test\")\n",
    "    torch.manual_seed(i)\n",
    "    server_private = server_private_vec[\"elltwo\"] \n",
    "    privmech_now = \"lapu\"\n",
    "    \n",
    "    \n",
    "    server_private.load_private_data_multinomial(\n",
    "        LDPclient.release_private(\n",
    "            privmech_now,\n",
    "            data_gen.generate_multinomial_data(p, sample_size),\n",
    "            d,\n",
    "            privacy_level,\n",
    "            device\n",
    "        ),\n",
    "        LDPclient.release_private(\n",
    "            privmech_now,\n",
    "            data_gen.generate_multinomial_data(p, sample_size),\n",
    "            d,\n",
    "            privacy_level,\n",
    "            device\n",
    "        ),\n",
    "        d,\n",
    "        device,\n",
    "        device\n",
    "        )\n",
    "    p_value_array[i,0], _ = server_private.release_p_value_permutation(n_permutation)\n",
    "\n",
    "elapsed = time.time() - t\n",
    "print(elapsed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### genrr + chi, chi-square asymptotics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1th test\n",
      "2th test\n",
      "3th test\n",
      "4th test\n",
      "5th test\n",
      "6th test\n",
      "7th test\n",
      "8th test\n",
      "9th test\n",
      "10th test\n",
      "0.23188209533691406\n"
     ]
    }
   ],
   "source": [
    "t = time.time()\n",
    "for i in range(n_test):\n",
    "    print(f\"{i+1}th test\")\n",
    "    torch.manual_seed(i)\n",
    "    server_private = server_private_vec[\"chi\"] \n",
    "    privmech_now = \"genrr\"\n",
    "    \n",
    "    \n",
    "    server_private.load_private_data_multinomial(\n",
    "        LDPclient.release_private(\n",
    "            privmech_now,\n",
    "            data_gen.generate_multinomial_data(p, sample_size),\n",
    "            d,\n",
    "            privacy_level,\n",
    "            device\n",
    "        ),\n",
    "        LDPclient.release_private(\n",
    "            privmech_now,\n",
    "            data_gen.generate_multinomial_data(p, sample_size),\n",
    "            d,\n",
    "            privacy_level,\n",
    "            device\n",
    "        ),\n",
    "        d,\n",
    "        device,\n",
    "        device\n",
    "        )\n",
    "    p_value_array[i,1], _ = server_private.release_p_value()\n",
    "\n",
    "elapsed = time.time() - t\n",
    "print(elapsed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### rappor + projchi, chi-square asymptotics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1th test\n",
      "2th test\n",
      "3th test\n",
      "4th test\n",
      "5th test\n",
      "6th test\n",
      "7th test\n",
      "8th test\n",
      "9th test\n",
      "10th test\n",
      "0.2753326892852783\n"
     ]
    }
   ],
   "source": [
    "t = time.time()\n",
    "for i in range(n_test):\n",
    "    print(f\"{i+1}th test\")\n",
    "    torch.manual_seed(i)\n",
    "    server_private = server_private_vec[\"projchi\"] \n",
    "    privmech_now = \"bitflip\"\n",
    "    \n",
    "    \n",
    "    server_private.load_private_data_multinomial(\n",
    "        LDPclient.release_private(\n",
    "            privmech_now,\n",
    "            data_gen.generate_multinomial_data(p, sample_size),\n",
    "            d,\n",
    "            privacy_level,\n",
    "            device\n",
    "        ),\n",
    "        LDPclient.release_private(\n",
    "            privmech_now,\n",
    "            data_gen.generate_multinomial_data(p, sample_size),\n",
    "            d,\n",
    "            privacy_level,\n",
    "            device\n",
    "        ),\n",
    "        d,\n",
    "        device,\n",
    "        device\n",
    "        )\n",
    "    p_value_array[i,2], _ = server_private.release_p_value()\n",
    "\n",
    "elapsed = time.time() - t\n",
    "print(elapsed)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LDPUtsEnvK40_windows",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
