{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mps\n",
      "tensor([0.2400, 0.2600, 0.2400, 0.2600])\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '/Users/jmmoon/Documents/GitHub/LDPUts')\n",
    "import gc\n",
    "from discretizer import discretizer\n",
    "from client import client\n",
    "import torch\n",
    "from server import server_ell2, server_multinomial_genrr, server_multinomial_bitflip, server_multinomial_bitflip_old\n",
    "from data_generator import data_generator\n",
    "from discretizer import discretizer\n",
    "import time\n",
    "import numpy as np\n",
    "from scipy.stats import chi2\n",
    "from utils import chi_sq_dist\n",
    "\n",
    "\n",
    "device = torch.device(\"mps\")\n",
    "print(device)\n",
    "\n",
    "sample_size = 10000\n",
    "privacy_level = 2.0\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "n_test = 300\n",
    "n_permutation = 9999\n",
    "significance_level = 0.05\n",
    "alphabet_size = 4\n",
    "\n",
    "p1 = torch.ones(alphabet_size).div(alphabet_size)\n",
    "\n",
    "bump_size = 0.01\n",
    "p2 = p1.add(\n",
    "    torch.remainder(\n",
    "    torch.tensor(range(alphabet_size)),\n",
    "    2\n",
    "    ).add(-1/2).mul(2).mul(bump_size)\n",
    ")\n",
    "print(p2)\n",
    "\n",
    "\n",
    "alphabet_size = 4\n",
    "    \n",
    "data_gen = data_generator()\n",
    "LDPclient = client()\n",
    "\n",
    "\n",
    "server_bitflip = server_multinomial_bitflip(privacy_level)\n",
    "server_bitflip_old = server_multinomial_bitflip_old(privacy_level)\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "grand_mean = torch.mean(torch.vstack((server_bitflip.data_y, server_bitflip.data_z)),0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.2356, -0.0122, -0.0137, -0.0122],\n",
       "        [-0.0122,  0.2362, -0.0108, -0.0148],\n",
       "        [-0.0137, -0.0108,  0.2365, -0.0115],\n",
       "        [-0.0122, -0.0148, -0.0115,  0.2359]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cov(torch.vstack((server_bitflip.data_y, server_bitflip.data_z)).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.2356, -0.0122, -0.0137, -0.0122],\n",
       "        [-0.0122,  0.2361, -0.0108, -0.0148],\n",
       "        [-0.0137, -0.0108,  0.2365, -0.0114],\n",
       "        [-0.0122, -0.0148, -0.0114,  0.2359]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(torch.cov(server_bitflip.data_y.T).mul(10000-1) + torch.cov(server_bitflip.data_z.T).mul(10000-1)).div(20000-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "cov = server_bitflip.data_y.sub(grand_mean).T.matmul(server_bitflip.data_y.sub(grand_mean)).add(\n",
    "    server_bitflip.data_z.sub(grand_mean).T.matmul(server_bitflip.data_z.sub(grand_mean))\n",
    ").div(20000-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3, 4]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[1,2,3,4][2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "  def _get_scaling_matrix(self):\n",
    "        mat_proj = self.get_proj_orth_one_space()\n",
    "        if self.cuda_device.type== \"cpu\":\n",
    "            prec_mat_est =  torch.tensor(numpy.linalg.inv(torch.cov(self.data.T).numpy()))\n",
    "        else:\n",
    "            prec_mat_est =  torch.linalg.inv(torch.cov(self.data.T))\n",
    "        return(\n",
    "            mat_proj.matmul(prec_mat_est.to(self.cuda_device)).matmul(mat_proj)\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "og\n",
      "tensor(3.3803)\n",
      "tensor(3.)\n",
      "tensor(3.3803)\n",
      "perm\n",
      "tensor(3.3803)\n",
      "og\n",
      "tensor([[3.3803]])\n",
      "tensor(3.)\n",
      "perm\n",
      "tensor([[3.3803]])\n",
      "pval: 0.33661818504333496 -- 0.33550000190734863(perm), 1th test, time elapsed 27.04398202896118\n",
      "pval old: 0.33661818504333496 -- 0.33550000190734863(perm old), 1th test, time elapsed 27.04398202896118\n",
      "\n",
      "og\n",
      "tensor(6.7960)\n",
      "tensor(3.)\n",
      "tensor(6.7960)\n",
      "perm\n",
      "tensor(6.7960)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 27\u001b[0m\n\u001b[1;32m     25\u001b[0m p_value_array[i,\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m=\u001b[39m server_bitflip\u001b[38;5;241m.\u001b[39mrelease_p_value()\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mperm\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 27\u001b[0m p_value_array[i,\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mserver_bitflip\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrelease_p_value_permutation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_permutation\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mog\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     30\u001b[0m p_value_array_old[i,\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m=\u001b[39m server_bitflip_old\u001b[38;5;241m.\u001b[39mrelease_p_value()\n",
      "File \u001b[0;32m~/Documents/GitHub/LDPUts/server.py:65\u001b[0m, in \u001b[0;36mserver.release_p_value_permutation\u001b[0;34m(self, n_permutation)\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_permutation):\n\u001b[1;32m     64\u001b[0m     torch\u001b[38;5;241m.\u001b[39mmanual_seed(i\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m10\u001b[39m)   \n\u001b[0;32m---> 65\u001b[0m     permuted_statistic_vec[i] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_statistic\u001b[49m\u001b[43m(\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandperm\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_1\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_2\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     67\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_p_value_proxy(permuted_statistic_vec, original_statistic))\n",
      "File \u001b[0;32m~/Documents/GitHub/LDPUts/server.py:200\u001b[0m, in \u001b[0;36mserver_multinomial_bitflip._get_statistic\u001b[0;34m(self, perm)\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_statistic\u001b[39m(\u001b[38;5;28mself\u001b[39m, perm):\n\u001b[1;32m    196\u001b[0m     proj_mu_hat_diff \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmv(\n\u001b[1;32m    197\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_proj_orth_one_space(),\n\u001b[1;32m    198\u001b[0m         torch\u001b[38;5;241m.\u001b[39msub(\n\u001b[1;32m    199\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_mean_y(perm),\n\u001b[0;32m--> 200\u001b[0m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_mean_z\u001b[49m\u001b[43m(\u001b[49m\u001b[43mperm\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    201\u001b[0m         )\n\u001b[1;32m    202\u001b[0m     )\n\u001b[1;32m    204\u001b[0m     scaling_constant \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mreciprocal( torch\u001b[38;5;241m.\u001b[39madd( \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_1\u001b[38;5;241m.\u001b[39mreciprocal(), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_2\u001b[38;5;241m.\u001b[39mreciprocal() ) )\n\u001b[1;32m    206\u001b[0m     statistic \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mdot(\n\u001b[1;32m    207\u001b[0m         proj_mu_hat_diff,\n\u001b[1;32m    208\u001b[0m         torch\u001b[38;5;241m.\u001b[39mlinalg\u001b[38;5;241m.\u001b[39msolve(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcov_est, proj_mu_hat_diff)\n\u001b[1;32m    209\u001b[0m     )\u001b[38;5;241m.\u001b[39mmul(scaling_constant)\n",
      "File \u001b[0;32m~/Documents/GitHub/LDPUts/server.py:111\u001b[0m, in \u001b[0;36mserver.get_mean_z\u001b[0;34m(self, perm)\u001b[0m\n\u001b[1;32m    110\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_mean_z\u001b[39m(\u001b[38;5;28mself\u001b[39m, perm):\n\u001b[0;32m--> 111\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_sum_z\u001b[49m\u001b[43m(\u001b[49m\u001b[43mperm\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mdiv(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_2)\n",
      "File \u001b[0;32m~/Documents/GitHub/LDPUts/server.py:105\u001b[0m, in \u001b[0;36mserver.get_sum_z\u001b[0;34m(self, perm)\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_sum_z\u001b[39m(\u001b[38;5;28mself\u001b[39m, perm ):\n\u001b[1;32m    104\u001b[0m     _, _, perm_toZ_fromY, perm_toZ_fromZ \u001b[38;5;241m=\u001b[39m utils\u001b[38;5;241m.\u001b[39msplit_perm(perm, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_1)\n\u001b[0;32m--> 105\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata_y\u001b[49m\u001b[43m[\u001b[49m\u001b[43mperm_toZ_fromY\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msum\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcuda_device_z )\u001b[38;5;241m.\u001b[39madd( \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata_z[perm_toZ_fromZ]\u001b[38;5;241m.\u001b[39msum(\u001b[38;5;241m0\u001b[39m) ))\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "p_value_array = np.zeros([n_test, 2])\n",
    "p_value_array_old = np.zeros([n_test, 2])\n",
    "\n",
    "\n",
    "for i in range(3):\n",
    "    t_start_i = time.time()\n",
    "    torch.manual_seed(i)\n",
    "    data_priv_y = LDPclient.release_bitflip(\n",
    "            data_gen.generate_multinomial_data(p1, sample_size),\n",
    "            alphabet_size,\n",
    "            privacy_level\n",
    "            )\n",
    "    data_priv_z = LDPclient.release_bitflip(\n",
    "            data_gen.generate_multinomial_data(p2, sample_size),\n",
    "            alphabet_size,\n",
    "            privacy_level\n",
    "    )\n",
    "    server_bitflip_old.load_private_data_multinomial_y(data_priv_y, alphabet_size)\n",
    "    server_bitflip_old.load_private_data_multinomial_z(data_priv_z, alphabet_size)\n",
    "\n",
    "    server_bitflip.load_private_data_multinomial_y(data_priv_y, alphabet_size)\n",
    "    server_bitflip.load_private_data_multinomial_z(data_priv_z, alphabet_size)\n",
    "\n",
    "    print(\"og\")\n",
    "    p_value_array[i,1] = server_bitflip.release_p_value()\n",
    "    print(\"perm\")\n",
    "    p_value_array[i,0] = server_bitflip.release_p_value_permutation(n_permutation)\n",
    "    \n",
    "    print(\"og\")\n",
    "    p_value_array_old[i,1] = server_bitflip_old.release_p_value()\n",
    "    print(\"perm\")\n",
    "    p_value_array_old[i,0] = server_bitflip_old.release_p_value_permutation(n_permutation)\n",
    "    \n",
    "    \n",
    "    t_end_i = time.time() - t_start_i\n",
    "    print(f\"pval: {p_value_array[i,1]} -- {p_value_array[i,0]}(perm), {i+1}th test, time elapsed {t_end_i}\")\n",
    "    print(f\"pval old: {p_value_array_old[i,1]} -- {p_value_array_old[i,0]}(perm old), {i+1}th test, time elapsed {t_end_i}\\n\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.0000e-04)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1/server_bitflip.n_1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
